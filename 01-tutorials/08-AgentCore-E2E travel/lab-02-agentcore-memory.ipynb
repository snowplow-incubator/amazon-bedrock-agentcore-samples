{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Personalize our agent by adding memory\n",
    "\n",
    "### Overview\n",
    "\n",
    "In Lab 1, you built a Travel Support Agent that worked well for a single user in a local session. However, real-world customer support needs to scale beyond a single user running in a local environment.\n",
    "\n",
    "When we run an **Agent in Production**, we'll need:\n",
    "- **Multi-User Support**: Handle thousands of customers simultaneously\n",
    "- **Persistent Storage**: Save conversations beyond session lifecycle\n",
    "- **Long-Term Learning**: Extract customer preferences and behavioral patterns\n",
    "- **Cross-Session Continuity**: Remember customers across different interactions\n",
    "\n",
    "**Workshop Progress:**\n",
    "- **Lab 1 (Done)**: Create Agent Prototype - Build a functional travel agent\n",
    "- **Lab 2 (Current)**: Enhance with Memory - Add conversation context and personalization\n",
    "- **Lab 3**: Scale with Gateway & Identity - Share tools across agents securely\n",
    "- **Lab 4**: Deploy to Production - Use AgentCore Runtime with observability\n",
    "- **Lab 5**: Build User Interface - Create a customer-facing application\n",
    "\n",
    "\n",
    "In this lab, you'll add the missing persistence and learning layer that transforms your Goldfish-Agent (forgets the conversation in seconds) into an smart personalized Assistant.\n",
    "\n",
    "Memory is a critical component of intelligence. While Large Language Models (LLMs) have impressive capabilities, they lack persistent memory across conversations. [Amazon Bedrock AgentCore Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-getting-started.html) addresses this limitation by providing a managed service that enables AI agents to maintain context over time, remember important facts, and deliver consistent, personalized experiences.\n",
    "\n",
    "AgentCore Memory operates on two levels:\n",
    "- **Short-Term Memory**: Immediate conversation context and session-based information that provides continuity within a single interaction or closely related sessions.\n",
    "- **Long-Term Memory**: Persistent information extracted and stored across multiple conversations, including facts, preferences, and summaries that enable personalized experiences over time.\n",
    "\n",
    "### Architecture for Lab 2\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_lab2_memory.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "*Multi-user agent with persistent short term and long term memory capabilities. *\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* **AWS Account** with appropriate permissions\n",
    "* **Python 3.10+** installed locally\n",
    "* **AWS CLI configured** with credentials\n",
    "* **Anthropic Claude 3.7** enabled on [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)\n",
    "* **Strands Agents** and other libraries installed in the next cells\n",
    "* These resources are created for you within an AWS workshop account\n",
    "    - AWS Lambda function \n",
    "    - AWS Lambda Execution IAM Role\n",
    "    - AgentCore Gateway IAM Role\n",
    "    - DynamoDB tables used by the AWS Lambda function. \n",
    "    - Cognito User Pool and User Pool Client\n",
    "#### Not using an AWS workshop account? \n",
    "\n",
    "**Note:** If you are running this as a self-paced lab you must run create the cloudformation resources as shown in the workshop self-paced steps. If you have not, then uncomment and run the below code segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Getting AWS Account ID...\n",
      "Region: ap-southeast-2\n",
      "Account ID: 485941242585\n",
      "ü™£ Using S3 bucket: travelagent112-485941242585-ap-southeast-2\n",
      "‚ÑπÔ∏è Bucket may already exist or be owned by you.\n",
      "üîç Verifying S3 bucket ownership...\n",
      "‚úÖ S3 bucket ownership verified\n",
      "üì¶ Zipping contents of prerequisite/lambda/python into lambda.zip...\n",
      "‚òÅÔ∏è Uploading lambda.zip to s3://travelagent112-485941242585-ap-southeast-2/lambda.zip...\n",
      "{\n",
      "    \"ETag\": \"\\\"71e583f3a3097e68cdd1724c76929f35\\\"\",\n",
      "    \"ServerSideEncryption\": \"AES256\"\n",
      "}\n",
      "‚òÅÔ∏è Uploading ddgs-layer.zip to s3://travelagent112-485941242585-ap-southeast-2/ddgs-layer.zip...\n",
      "{\n",
      "    \"ETag\": \"\\\"0f2b60895990988b94f7258caa5b68ba\\\"\",\n",
      "    \"ServerSideEncryption\": \"AES256\"\n",
      "}\n",
      "üîß Starting deployment of infrastructure stack with LambdaS3Bucket = travelagent112-485941242585-ap-southeast-2...\n",
      "üöÄ Deploying CloudFormation stack: TravelAgentStackInfra\n",
      "Uploading to 5f85ecbd53436ab81107e8415568c3d1.template  57464 / 57464.0  (100.00%)\n",
      "Waiting for changeset to be created..\n",
      "Waiting for stack create/update to complete\n",
      "Successfully created/updated stack - TravelAgentStackInfra\n",
      "‚úÖ Stack TravelAgentStackInfra deployed successfully.\n",
      "üîß Starting deployment of Cognito stack...\n",
      "üöÄ Deploying CloudFormation stack: TravelAgentStackCognito\n",
      "\n",
      "Waiting for changeset to be created..\n",
      "\n",
      "No changes to deploy. Stack TravelAgentStackCognito is up to date\n",
      "‚ÑπÔ∏è No updates for stack TravelAgentStackCognito, continuing...\n",
      "‚úÖ Deployment complete.\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/prereq.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n",
    "Let's import the libraries for AgentCore Memory. For it, we will use the [Amazon Bedrock AgentCore Python SDK](https://github.com/aws/bedrock-agentcore-sdk-python), a lightweight wrapper that helps you working with AgentCore capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Import agentCore Memory\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.constants import StrategyType\n",
    "\n",
    "from strands.hooks import AfterInvocationEvent, HookProvider, HookRegistry, MessageAddedEvent\n",
    "\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "REGION = boto_session.region_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from lab_helpers.utils import get_ssm_parameter, put_ssm_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Bedrock AgentCore Memory resources\n",
    "\n",
    "Amazon Bedrock AgentCore Memory is a fully managed service that provides persistent memory capabilities for AI agents.\n",
    "\n",
    "#### AgentCore Memory Concepts:\n",
    "\n",
    "1. **Short-Term Memory (STM)**: Immediately stores conversation context within the session\n",
    "2. **Long-Term Memory (LTM)**: Asynchronously processes STM to extract meaningful patterns, preferences and facts\n",
    "3. **Memory Strategies**: Different approaches for extracting and organizing information:\n",
    "   - **USER_PREFERENCE**: Learns customer preferences, behaviors, and patterns\n",
    "   - **SEMANTIC**: Stores factual information using vector embeddings for similarity search\n",
    "4. **Namespaces**: Logical grouping of memories by customer and context type. We'll create these two namespaces:\n",
    "- `support/customer/{actorId}/preferences`: Customer preferences and behavioral patterns\n",
    "- `support/customer/{actorId}/semantic`: Factual information and conversation history\n",
    "\n",
    "This structure enables multi-tenant memory where each customer's information is isolated and easily retrievable.\n",
    "\n",
    "#### Memory Creation Process:\n",
    "\n",
    "Creating memory resources involves provisioning the underlying infrastructure (vector databases, processing pipelines, etc.). This typically takes 2-3 minutes as AWS sets up the managed services behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_client = MemoryClient(region_name=REGION)\n",
    "memory_name = \"TravelAgentMemory\"\n",
    "\n",
    "def create_or_get_memory_resource():\n",
    "    try:\n",
    "        memory_id = get_ssm_parameter(\"/app/travelagent/agentcore/memory_id\")\n",
    "        memory_client.gmcp_client.get_memory(memoryId=memory_id)\n",
    "        return memory_id\n",
    "    except:\n",
    "        try:\n",
    "            strategies = [\n",
    "                {\n",
    "                    StrategyType.USER_PREFERENCE.value: {\n",
    "                        \"name\": \"CustomerPreferences\",\n",
    "                        \"description\": \"Captures customer preferences and behavior\",\n",
    "                        \"namespaces\": [\"travelagent/customer/{actorId}/preferences\"],\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    StrategyType.SEMANTIC.value: {\n",
    "                        \"name\": \"TravelAgentSemantic\",\n",
    "                        \"description\": \"Stores facts from conversations\",\n",
    "                        \"namespaces\": [\"travelagent/customer/{actorId}/semantic\"],\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "            print(\"Creating AgentCore Memory resources. This will take 2-3 minutes...\")\n",
    "            print(\"While we wait, let's understand what's happening behind the scenes:\")\n",
    "            print(\"‚Ä¢ Setting up managed vector databases for semantic search\")\n",
    "            print(\"‚Ä¢ Configuring memory extraction pipelines\")\n",
    "            print(\"‚Ä¢ Provisioning secure, multi-tenant storage\")\n",
    "            print(\"‚Ä¢ Establishing namespace isolation for customer data\")\n",
    "            # *** AGENTCORE MEMORY USAGE *** - Create memory resource with semantic strategy\n",
    "            response = memory_client.create_memory_and_wait(\n",
    "                name=memory_name,\n",
    "                description=\"Travel agent memory\",\n",
    "                strategies=strategies,\n",
    "                event_expiry_days=7,          # Memories expire after 7 days\n",
    "            )\n",
    "            memory_id = response[\"id\"]\n",
    "            try:\n",
    "                put_ssm_parameter(\"/app/travelagent/agentcore/memory_id\", memory_id)\n",
    "            except:\n",
    "                raise\n",
    "            return memory_id\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create memory resource: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AgentCore Memory created successfully!\n",
      "Memory ID: TravelAgentMemory-jEgT5dAIC4\n"
     ]
    }
   ],
   "source": [
    "memory_id = create_or_get_memory_resource()\n",
    "if memory_id:\n",
    "    print(\"‚úÖ AgentCore Memory created successfully!\")\n",
    "    print(f\"Memory ID: {memory_id}\")\n",
    "else:\n",
    "    print(\"Memory resource not created. Try Again !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Seed previous customer interactions\n",
    "\n",
    "**Why are we seeding memory?**\n",
    "\n",
    "In production, agents accumulate memory naturally through customer interactions. However, for this lab, we're seeding historical conversations to demonstrate how Long-Term Memory (LTM) works without waiting for real conversations.\n",
    "\n",
    "**How memory processing works:**\n",
    "1. `create_event` stores interactions in **Short-Term Memory** (STM) instantly\n",
    "2. STM is asynchronously processed by **Long-Term Memory** strategies\n",
    "3. LTM extracts patterns, preferences, and facts for future retrieval\n",
    "\n",
    "Let's seed some customer history to see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Arn: arn:aws:bedrock-agentcore:ap-southeast-2:485941242585:memory/CustomerSupportMemory-jHBX2S7Kjp\n",
      "Memory ID: CustomerSupportMemory-jHBX2S7Kjp\n",
      "--------------------------------------------------------------------\n",
      "Memory Arn: arn:aws:bedrock-agentcore:ap-southeast-2:485941242585:memory/TravelAgentMemory-jEgT5dAIC4\n",
      "Memory ID: TravelAgentMemory-jEgT5dAIC4\n",
      "--------------------------------------------------------------------\n",
      "‚úÖ Seeded customer history successfully\n",
      "üìù Interactions saved to Short-Term Memory\n",
      "‚è≥ Long-Term Memory processing will begin automatically...\n"
     ]
    }
   ],
   "source": [
    "# List existing memory resources\n",
    "for memory in memory_client.list_memories():\n",
    "    print(f\"Memory Arn: {memory.get('arn')}\")\n",
    "    print(f\"Memory ID: {memory.get('id')}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "# Seed with previous customer interactions\n",
    "CUSTOMER_ID = \"customer_001\"\n",
    "\n",
    "# previous_interactions = [\n",
    "#     (\"I'm having issues with my MacBook Pro overheating during video editing.\",\"USER\"),\n",
    "#     (\"I can help with that thermal issue. For video editing workloads, let's check your Activity Monitor and adjust performance settings. Your MacBook Pro order #MB-78432 is still under warranty.\", \"ASSISTANT\"),\n",
    "#     (\"What's the return policy on gaming headphones? I need low latency for competitive FPS games\", \"USER\"),\n",
    "#     (\"For gaming headphones, you have 30 days to return. Since you're into competitive FPS, I'd recommend checking the audio latency specs - most gaming models have <40ms latency.\", \"ASSISTANT\"),\n",
    "#     (\"I need a laptop under $1200 for programming. Prefer 16GB RAM minimum and good Linux compatibility. I like ThinkPad models.\", \"USER\"),\n",
    "#     (\"Perfect! For development work, I'd suggest looking at our ThinkPad E series or Dell XPS models. Both have excellent Linux support and 16GB RAM options within your budget.\", \"ASSISTANT\"),\n",
    "# ]\n",
    "\n",
    "previous_interactions = [\n",
    "    (\"Bangkok looks really nice, I'd like to go there\", \"USER\")\n",
    "]\n",
    "\n",
    "# Save previous interactions\n",
    "if memory_id:\n",
    "    try:\n",
    "        memory_client.create_event(\n",
    "            memory_id=memory_id,\n",
    "            actor_id=CUSTOMER_ID,\n",
    "            session_id=\"previous_session\",\n",
    "            messages=previous_interactions\n",
    "        )\n",
    "        print(\"‚úÖ Seeded customer history successfully\")\n",
    "        print(\"üìù Interactions saved to Short-Term Memory\")\n",
    "        print(\"‚è≥ Long-Term Memory processing will begin automatically...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error seeding history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Memory Processing\n",
    "\n",
    "After creating events with `create_event`, AgentCore Memory processes the data in two stages:\n",
    "\n",
    "1. **Immediate**: Messages stored in Short-Term Memory (STM)\n",
    "2. **Asynchronous**: STM processed into Long-Term Memory (LTM) strategies\n",
    "\n",
    "LTM processing typically takes 20-30 seconds as the system:\n",
    "- Analyzes conversation patterns\n",
    "- Extracts customer preferences and behaviors\n",
    "- Creates semantic embeddings for factual information\n",
    "- Organizes memories by namespace for efficient retrieval\n",
    "\n",
    "Let's check if our Long-Term Memory processing is complete by retrieving customer preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for processed Long-Term Memories...\n",
      "‚úÖ Found 2 preference memories after 0 seconds!\n",
      "üéØ AgentCore Memory automatically extracted these customer preferences from our seeded conversations:\n",
      "================================================================================\n",
      "  1. {\"context\":\"The user is asking for warm destination recommendations, indicating they prefer warm weather when traveling.\",\"preference\":\"Prefers warm weather destinations for travel\",\"categories\":[\"travel\",\"weather\",\"climate\"]}\n",
      "  2. {\"context\":\"The user explicitly expressed interest in visiting Bangkok, stating it looks really nice and they'd like to go there.\",\"preference\":\"Interested in visiting Bangkok\",\"categories\":[\"travel\",\"destinations\",\"Asia\"]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait for Long-Term Memory processing to complete\n",
    "print(\"üîç Checking for processed Long-Term Memories...\")\n",
    "retries = 0\n",
    "max_retries = 6  # 1 minute wait\n",
    "\n",
    "# travelagent/customer/{actorId}/preferences\n",
    "\n",
    "while retries < max_retries:\n",
    "    memories = memory_client.retrieve_memories(\n",
    "        memory_id=memory_id,\n",
    "        namespace=f\"travelagent/customer/{CUSTOMER_ID}/preferences\",\n",
    "        query=\"can you summarize where the user wants to go\"\n",
    "    )\n",
    "    \n",
    "    if memories:\n",
    "        print(f\"‚úÖ Found {len(memories)} preference memories after {retries * 10} seconds!\")\n",
    "        break\n",
    "    \n",
    "    retries += 1\n",
    "    if retries < max_retries:\n",
    "        print(f\"‚è≥ Still processing... waiting 10 more seconds (attempt {retries}/{max_retries})\")\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Memory processing is taking longer than expected. This can happen with overloading..\")\n",
    "        break\n",
    "\n",
    "print(\"üéØ AgentCore Memory automatically extracted these customer preferences from our seeded conversations:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Semantic Memory\n",
    "\n",
    "Semantic memory stores factual information from conversations using vector embeddings. This enables similarity-based retrieval of relevant facts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† AgentCore Memory identified these factual details from conversations:\n",
      "================================================================================\n",
      "  1. The user is seeking recommendations for warm destinations to visit.\n",
      "  2. The user prefers warm weather destinations for travel.\n",
      "  3. The user would like to visit Bangkok and thinks it looks really nice.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Retrieve semantic memories (factual information)\n",
    "while True:\n",
    "    semantic_memories = memory_client.retrieve_memories(\n",
    "        memory_id=memory_id,\n",
    "        namespace=f\"travelagent/customer/{CUSTOMER_ID}/semantic\",\n",
    "        query=\"information on the technical support issue\"\n",
    "    )\n",
    "    print(\"üß† AgentCore Memory identified these factual details from conversations:\")\n",
    "    print(\"=\" * 80)\n",
    "    if memories:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "for i, memory in enumerate(semantic_memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement Strands Hooks to save and retrieve agent interactions\n",
    "\n",
    "Now we'll integrate AgentCore Memory with our agent using Strands' hook system. This creates an automatic memory layer that works seamlessly with any agent conversation.\n",
    "\n",
    "- **MessageAddedEvent**: Triggered when messages are added to the conversation, allowing us to retrieve and inject customer context\n",
    "- **AfterInvocationEvent**: Fired after agent responses, enabling automatic storage of interactions to memory\n",
    "\n",
    "The hook system ensures memory operations happen automatically without manual intervention, creating a seamless experience where customer context is preserved across conversations.\n",
    "\n",
    "To create the hooks we will extend the `HookProvider` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelMemoryHooks(HookProvider):\n",
    "    \"\"\"Memory hooks for travel agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, memory_id: str, client: MemoryClient, actor_id: str, session_id: str\n",
    "    ):\n",
    "        self.memory_id = memory_id\n",
    "        self.client = client\n",
    "        self.actor_id = actor_id\n",
    "        self.session_id = session_id\n",
    "        self.namespaces = {\n",
    "            i[\"type\"]: i[\"namespaces\"][0]\n",
    "            for i in self.client.get_memory_strategies(self.memory_id)\n",
    "        }\n",
    "\n",
    "    def retrieve_customer_context(self, event: MessageAddedEvent):\n",
    "        \"\"\"Retrieve customer context before processing travel query\"\"\"\n",
    "        # TODO: is this where we should incorporate calling signals?\n",
    "        messages = event.agent.messages\n",
    "        if (\n",
    "            messages[-1][\"role\"] == \"user\"\n",
    "            and \"toolResult\" not in messages[-1][\"content\"][0]\n",
    "        ):\n",
    "            user_query = messages[-1][\"content\"][0][\"text\"]\n",
    "\n",
    "            try:\n",
    "                all_context = []\n",
    "\n",
    "                for context_type, namespace in self.namespaces.items():\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Retrieve customer context from each namespace\n",
    "                    memories = self.client.retrieve_memories(\n",
    "                        memory_id=self.memory_id,\n",
    "                        namespace=namespace.format(actorId=self.actor_id),\n",
    "                        query=user_query,\n",
    "                        top_k=3,\n",
    "                    )\n",
    "                    # Post-processing: Format memories into context strings\n",
    "                    for memory in memories:\n",
    "                        if isinstance(memory, dict):\n",
    "                            content = memory.get(\"content\", {})\n",
    "                            if isinstance(content, dict):\n",
    "                                text = content.get(\"text\", \"\").strip()\n",
    "                                if text:\n",
    "                                    all_context.append(\n",
    "                                        f\"[{context_type.upper()}] {text}\"\n",
    "                                    )\n",
    "\n",
    "                # Inject customer context into the query\n",
    "                if all_context:\n",
    "                    context_text = \"\\n\".join(all_context)\n",
    "                    original_text = messages[-1][\"content\"][0][\"text\"]\n",
    "                    messages[-1][\"content\"][0][\n",
    "                        \"text\"\n",
    "                    ] = f\"Customer Context:\\n{context_text}\\n\\n{original_text}\"\n",
    "                    logger.info(f\"Retrieved {len(all_context)} customer context items\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to retrieve customer context: {e}\")\n",
    "\n",
    "    def save_travel_interaction(self, event: AfterInvocationEvent):\n",
    "        \"\"\"Save customer travel interaction after agent response\"\"\"\n",
    "        try:\n",
    "            messages = event.agent.messages\n",
    "            if len(messages) >= 2 and messages[-1][\"role\"] == \"assistant\":\n",
    "                # Get last customer query and agent response\n",
    "                customer_query = None\n",
    "                agent_response = None\n",
    "\n",
    "                for msg in reversed(messages):\n",
    "                    if msg[\"role\"] == \"assistant\" and not agent_response:\n",
    "                        agent_response = msg[\"content\"][0][\"text\"]\n",
    "                    elif (\n",
    "                        msg[\"role\"] == \"user\"\n",
    "                        and not customer_query\n",
    "                        and \"toolResult\" not in msg[\"content\"][0]\n",
    "                    ):\n",
    "                        customer_query = msg[\"content\"][0][\"text\"]\n",
    "                        break\n",
    "\n",
    "                if customer_query and agent_response:\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Save the travel interaction\n",
    "                    self.client.create_event(\n",
    "                        memory_id=self.memory_id,\n",
    "                        actor_id=self.actor_id,\n",
    "                        session_id=self.session_id,\n",
    "                        messages=[\n",
    "                            (customer_query, \"USER\"),\n",
    "                            (agent_response, \"ASSISTANT\"),\n",
    "                        ],\n",
    "                    )\n",
    "                    logger.info(\"Saved travel interaction to memory\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save travel interaction: {e}\")\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        \"\"\"Register customer support memory hooks\"\"\"\n",
    "        # TODO: consider adding a separate hook here for Signals?\n",
    "        registry.add_callback(MessageAddedEvent, self.retrieve_customer_context)\n",
    "        registry.add_callback(AfterInvocationEvent, self.save_travel_interaction)\n",
    "        logger.info(\"Travel memory hooks registered\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Travel Agent with memory\n",
    "\n",
    "Next, we will implement the Travel Agent just as we did in Lab 1, but this time we instantiate the class `TravelMemoryHooks` and we pass the memory hook to the agent contructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# TODO: note, this import is the equivalent of what happens in the first notebook, just replicated in a file\n",
    "from lab_helpers.lab1_strands_agent import (\n",
    "    SYSTEM_PROMPT,\n",
    "    get_destination_info, web_search,\n",
    "    get_experience_info, MODEL_ID, get_all_experiences, get_signals\n",
    ")\n",
    "\n",
    "CUSTOMER_ID = \"customer_001\"\n",
    "SESSION_ID = str(uuid.uuid4())\n",
    "memory_hooks = TravelMemoryHooks(memory_id, memory_client, CUSTOMER_ID, SESSION_ID)\n",
    "\n",
    "\n",
    "# Initialize the Bedrock model (Anthropic Claude 3.7 Sonnet)\n",
    "model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    region_name=REGION\n",
    ")\n",
    "\n",
    "# Create the customer support agent with all 5 tools\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    hooks=[memory_hooks], # Pass Memory Hooks\n",
    "    tools=[\n",
    "        get_destination_info,      # Tool 1: Simple product information lookup\n",
    "        get_experience_info,      # Tool 2: Simple return policy lookup\n",
    "        web_search,\n",
    "        get_signals,\n",
    "        get_all_experiences\n",
    "    ],\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test Personalized Agent\n",
    "\n",
    "Let's test our memory-enhanced agent! Watch how it uses the customer's historical preferences to provide personalized recommendations.\n",
    "\n",
    "The agent will automatically:\n",
    "1. Retrieve relevant customer context from memory\n",
    "2. Use that context to personalize the response\n",
    "3. Save this new interaction for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Testing destinations recommendations with customer memory...\n",
      "\n",
      "\n",
      "I'd be happy to recommend some warm destinations in Southeast Asia based on your preferences! Since you've expressed interest in Bangkok and enjoy warm weather destinations, let's start there and explore some other great options in the region.\n",
      "\n",
      "Let me get some detailed information about Bangkok for you first:\n",
      "Tool #1: get_destination_info\n",
      "Now, let me gather information about some other warm destinations in Southeast Asia that you might enjoy:\n",
      "Tool #2: get_destination_info\n",
      "Let me try getting information about some other warm destinations:\n",
      "Tool #3: get_destination_info\n",
      "Let me search for more information about warm destinations in Southeast Asia:\n",
      "Tool #4: web_search\n",
      "Based on the information I've gathered, here are some warm weather destinations in Southeast Asia I'd recommend for you:\n",
      "\n",
      "## üåÜ Bangkok, Thailand\n",
      "Since you've specifically expressed interest in Bangkok, this is a perfect starting point! Bangkok offers:\n",
      "- Vibrant street food scene with authentic Thai cuisine\n",
      "- Beautiful temples like Wat Arun and Grand Palace\n",
      "- Exciting nightlife and shopping opportunities\n",
      "- Year-round warm weather with temperatures typically between 26-35¬∞C (79-95¬∞F)\n",
      "- Excellent transportation hub for exploring other parts of Thailand\n",
      "\n",
      "## üèùÔ∏è Other Warm Weather Destinations in Southeast Asia\n",
      "\n",
      "### üèñÔ∏è Phuket, Thailand\n",
      "- Beautiful beaches with clear blue waters\n",
      "- Wide range of water activities (snorkeling, diving, island hopping)\n",
      "- Vibrant nightlife in Patong Beach\n",
      "- Luxurious resorts and affordable accommodations\n",
      "- Warm tropical weather year-round\n",
      "\n",
      "### üå∫ Bali, Indonesia\n",
      "- Stunning beaches, lush rice terraces, and volcanic landscapes\n",
      "- Rich cultural experiences with traditional Balinese temples\n",
      "- Popular areas like Ubud for yoga and wellness retreats\n",
      "- Great surfing spots in Kuta and Uluwatu\n",
      "- Warm weather with average temperatures of 26-33¬∞C (79-91¬∞F)\n",
      "\n",
      "### üå¥ Krabi, Thailand\n",
      "- Dramatic limestone cliffs and emerald waters\n",
      "- Famous Railay Beach accessible only by boat\n",
      "- Rock climbing opportunities\n",
      "- Island hopping to Phi Phi Islands\n",
      "- Consistently warm tropical climate\n",
      "\n",
      "### üèôÔ∏è Ho Chi Minh City, Vietnam\n",
      "- Vibrant urban experience with French colonial architecture\n",
      "- Amazing Vietnamese cuisine and street food\n",
      "- Warm year-round climate\n",
      "- Rich historical sites like War Remnants Museum\n",
      "- Gateway to exploring southern Vietnam\n",
      "\n",
      "### üáµüá≠ Palawan, Philippines\n",
      "- Voted one of the world's most beautiful islands\n",
      "- El Nido's stunning lagoons and limestone formations\n",
      "- Underground River in Puerto Princesa (UNESCO site)\n",
      "- Warm tropical weather perfect for beach lovers\n",
      "- Excellent snorkeling and diving opportunities\n",
      "\n",
      "All these destinations feature warm weather year-round, making them perfect for travelers who prefer warmer climates. Would you like more specific information about any of these destinations or would you prefer recommendations for a particular time of year?"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéß Testing destinations recommendations with customer memory...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response1 = \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhich destinations would you recommend for me?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/poplin/amazon-bedrock-agentcore-samples/.venv/lib/python3.11/site-packages/strands/agent/agent.py:408\u001b[39m, in \u001b[36mAgent.__call__\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    407\u001b[39m     future = executor.submit(execute)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"üéß Testing destinations recommendations with customer memory...\\n\\n\")\n",
    "response1 = agent(\"Which destinations would you recommend for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíª Testing travel preferences...\n",
      "\n",
      "\n",
      "Based on the information you've shared with me, your preferred travel criteria include:\n",
      "\n",
      "1. **Warm Weather Destinations** - You've indicated a preference for places with warm climates when traveling. This is one of your primary considerations when choosing destinations.\n",
      "\n",
      "2. **Interest in Southeast Asia** - Particularly Bangkok, Thailand, which you've specifically mentioned looks really nice and is a place you'd like to visit.\n",
      "\n",
      "Beyond these specific preferences you've shared, I don't have additional information about your travel criteria such as:\n",
      "- Budget preferences\n",
      "- Preferred accommodation types\n",
      "- Interest in specific activities (adventure, culture, relaxation, etc.)\n",
      "- Length of typical trips\n",
      "- Solo travel or with companions\n",
      "- Urban vs. natural environments\n",
      "- Food preferences or dietary requirements\n",
      "\n",
      "Would you like to share more about these aspects of your travel preferences? This would help me provide even more tailored recommendations for warm weather destinations in Southeast Asia that would match your specific travel style and interests."
     ]
    }
   ],
   "source": [
    "# TODO: change this to something different...\n",
    "print(\"\\nüíª Testing travel preferences...\\n\\n\")\n",
    "response2 = agent(\"What are my preferred travel criteria?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the Agent remembers:\n",
    "‚Ä¢ Location interest\n",
    "* Climate interest\n",
    "\n",
    "This is the power of AgentCore Memory - persistent, personalized customer experiences!\n",
    "\n",
    "## Congratulations! üéâ\n",
    "\n",
    "You have successfully completed **Lab 2: Add memory to the Travel Agent**!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "- Created a serverless managed memory with Amazon Bedrock AgentCore Memory\n",
    "- Implemented long-term memory to store User-Preferences and Semantic (Factual) information.\n",
    "- Integrated AgentCore Memory with the travel Agent using the hook mechanism provided by Strands Agents\n",
    "\n",
    "##### Next Up [Lab 3 - Scaling with Gateway and Identity  ‚Üí](lab-03-agentcore-gateway.ipynb)\n",
    "\n",
    "## Resources\n",
    "- [Amazon Bedrock Agent Core Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html)\n",
    "- [Amazon Bedrock AgentCore Memory Deep Dive blog](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-memory-building-context-aware-agents/)\n",
    "- [Strands Agents Hooks Documentation](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/hooks/?h=hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
